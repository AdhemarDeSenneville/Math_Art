{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzU43CibKfIPsDHpFQ1QjP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdhemarDeSenneville/Math_Art/blob/main/CW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IzPnm3mQthwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066c0cf6-8ece-4323-e71b-3b3e7713b4aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import librosa\n",
        "import torch.nn as nn\n",
        "import torchaudio\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import copy\n",
        "import Utils"
      ],
      "metadata": {
        "id": "Zl-TOpsfuvwS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import TrivialAugmentWide,AugMix,AutoAugment,RandAugment,Resize,ToTensor,Compose,ToTensor\n",
        "from torch.utils.data import DataLoader,Dataset, random_split\n",
        "import torch.nn.functional as F\n",
        "\n"
      ],
      "metadata": {
        "id": "WIdvA5s8zTjG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"/content/gdrive/MyDrive/genres_original\"\n",
        "classes = os.listdir(root_dir)\n",
        "num_classes = len(classes)"
      ],
      "metadata": {
        "id": "tJrl2sOX5012"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#device"
      ],
      "metadata": {
        "id": "ywpKg_x4JTl6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioClassificationDataset(Dataset):\n",
        "    def __init__(self, root_dir, frame_size, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.classes = os.listdir(root_dir)\n",
        "        self.transform = transform\n",
        "        self.frame_size = frame_size\n",
        "        self.sample_length = 675808 + frame_size - 675808%frame_size\n",
        "        \n",
        "        self.file_list = []\n",
        "        for class_idx, class_name in enumerate(self.classes):\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            for filename in os.listdir(class_dir):\n",
        "                if filename.endswith('.wav'):\n",
        "                    file_path = os.path.join(class_dir, filename)\n",
        "                    self.file_list.append((file_path, class_idx))\n",
        "        \n",
        "        #self.compute_max_length()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def compute_max_length(self):\n",
        "\n",
        "        for file in self.file_list:\n",
        "            audio, sample_rate = torchaudio.load(file[0])\n",
        "            size = audio.size()[1]\n",
        "            if size > self.sample_length:\n",
        "              self.sample_length = size\n",
        "\n",
        "        print(\"Max sample length :\",self.sample_length)\n",
        "        self.sample_length + self.frame_size - self.sample_length%self.frame_size\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        # Load audio file using librosa\n",
        "        audio, sample_rate = torchaudio.load(self.file_list[idx][0])\n",
        "        class_idx = self.file_list[idx][1]\n",
        "\n",
        "        # Do padding\n",
        "        audio = F.pad(audio, (0, self.sample_length - audio.shape[-1]), \"constant\", 0)\n",
        "        audio = audio.view(-1,self.frame_size)\n",
        "        # Apply transform if specified\n",
        "        if self.transform:\n",
        "            audio = self.transform(audio)\n",
        "        \n",
        "        # Convert class index to one-hot vector\n",
        "        #label = torch.zeros(len(self.classes))\n",
        "        #label[class_idx] = 1\n",
        "        \n",
        "        return audio, class_idx"
      ],
      "metadata": {
        "id": "6xr7f7kI4Iwu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_size = 256\n",
        "\n",
        "Dataset = AudioClassificationDataset(root_dir,frame_size)\n",
        "\n",
        "lengths = [800, 200]\n",
        "train_d,valid_d=random_split(Dataset,lengths)\n",
        "\n",
        "# Checking input tensor shape\n",
        "img, label = Dataset.__getitem__(42)\n",
        "img_size = img.size()\n",
        "print(\"Image size :\",img_size)\n",
        "\n",
        "# Create the Train and Test Loaders \n",
        "dataloader_train = DataLoader(train_d, batch_size=32, shuffle=True)\n",
        "dataloader_test = DataLoader(valid_d, batch_size=32, shuffle=True)\n",
        "\n",
        "# Checking batch tensor info\n",
        "itr=iter(dataloader_train)\n",
        "item,label =next(itr)\n",
        "print(\"Batch info | type: \",type(item),\"| size:\",item.size(),\"| label size :\",label.size(),\"|\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbaZaoYn6_pI",
        "outputId": "193bc2f7-fe43-4cb6-e475-c796aec60151"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size : torch.Size([2640, 256])\n",
            "Batch info | type:  <class 'torch.Tensor'> | size: torch.Size([32, 2640, 256]) | label size : torch.Size([32]) |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Fbjpv3dIgr3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g02M1hNgJERQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fcn = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "f20YTUjrgAoq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model,loader):\n",
        "    model.eval()\n",
        "    epoch_loss=0.\n",
        "    epoch_acc = 0\n",
        "    count = 0\n",
        "    length = len(loader) * loader.batch_size\n",
        "    for imgs,labels in loader:\n",
        "        with torch.no_grad():\n",
        "            outputs=model(imgs)\n",
        "            loss=loss_fcn(outputs,labels)\n",
        "            epoch_loss+=loss.item()\n",
        "            \n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            epoch_acc += torch.sum(preds == labels.data)\n",
        "\n",
        "    return epoch_loss/len(loader), epoch_acc/length"
      ],
      "metadata": {
        "id": "krSNPlX0Jii8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "epoch_number = 10\n",
        "\n",
        "stop_befor = 3"
      ],
      "metadata": {
        "id": "CXS4YczXJi2A"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classification(Net):\n",
        "\n",
        "    test_loss_hist = []\n",
        "    train_loss_hist = []\n",
        "    test_acc_hist = []\n",
        "    train_acc_hist = []\n",
        "    mean_grad_hist = []\n",
        "    best_acc = 0\n",
        "\n",
        "    optimizer=torch.optim.Adam(Net.parameters(),lr=learning_rate) \n",
        "\n",
        "    for epoch in range(epoch_number):\n",
        "        Net.train()\n",
        "        epoch_loss=0\n",
        "        count=0\n",
        "        mean_grad=0\n",
        "        p = Utils.ProgressBare(len(dataloader_train),Size=50,Mode=\"Normal\",Freq=0.1)\n",
        "        \n",
        "        for imgs,labels in dataloader_train:\n",
        "              \n",
        "              count+=1\n",
        "            # uses the .forward() method to get y_hat\n",
        "              y_hat=Net(imgs)\n",
        "            # as before\n",
        "              loss=loss_fcn(y_hat,labels)\n",
        "            # Computes the gradients and saves them in the appropriate .grad\n",
        "              loss.backward()\n",
        "            # updates the parameters using the computed .grad\n",
        "              optimizer.step()\n",
        "            # zero the .grad values so that they don't accumulate\n",
        "              ###mean_grad_batch = get_mean_grad(Net)\n",
        "              ###mean_grad += mean_grad_batch\n",
        "              optimizer.zero_grad()\n",
        "              epoch_loss+=loss.item()\n",
        "              p.Update(\"Epoch \"+str(epoch+1)+\"/\"+str(epoch_number)\n",
        "                       +\" | Loss : \"+str(epoch_loss/count)[:5]\n",
        "                       +\" | MeanGrad \"+str(\"mean_grad_batch\")[:5])\n",
        "        \n",
        "        test_loss, test_acc = predict(Net,dataloader_test)\n",
        "        train_loss, train_acc = predict(Net,dataloader_train)\n",
        "\n",
        "        p.End(\"Test Loss : \"+str(test_loss)[:5]+\" Train Loss : \"+str(train_loss)[:5])\n",
        "\n",
        "        train_loss_hist.append(train_loss)\n",
        "        train_acc_hist.append(train_acc)\n",
        "        test_loss_hist.append(test_loss)\n",
        "        test_acc_hist.append(test_acc)\n",
        "\n",
        "        mean_grad_hist.append(mean_grad/count)\n",
        "\n",
        "        if  test_acc > best_acc:\n",
        "          stop_count = 0\n",
        "          best_acc = test_acc\n",
        "          best_model_wts = copy.deepcopy(Net.state_dict())\n",
        "        else:\n",
        "          stop_count +=1\n",
        "          if stop_count>stop_befor:\n",
        "            break\n",
        "\n",
        "        \n",
        "\n",
        "    plt.plot(train_loss_hist, label='Train')\n",
        "    plt.plot(test_loss_hist, label='Test')\n",
        "\n",
        "    # Add title and axis labels\n",
        "    plt.legend()\n",
        "    plt.title('Loss history')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(test_acc_hist, label='Train')\n",
        "    plt.plot(test_acc_hist, label='Test')\n",
        "    # Add title and axis labels\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy history')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Best Test Accuracy :\",best_acc)\n",
        "    \n",
        "    Net.load_state_dict(best_model_wts)\n",
        "    return Net"
      ],
      "metadata": {
        "id": "wp7w5OlviZB-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(AudioLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=1, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Set initial hidden and cell states\n",
        "        h0 = torch.zeros(1, x.size(0), self.lstm.hidden_size).to(device=x.device)\n",
        "        c0 = torch.zeros(1, x.size(0), self.lstm.hidden_size).to(device=x.device)\n",
        "\n",
        "        # Forward propagate LSTM\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "\n",
        "        # Decode the hidden state of the last time step\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "XJgCdEkGJEh_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"test\")\n",
        "LSTM_NET  = AudioLSTM(frame_size,frame_size)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxYxMshrinof",
        "outputId": "07d02f4a-8f73-4274-b98a-285eddd24664"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_NET = train_classification(LSTM_NET)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhfTDAKrioCG",
        "outputId": "4920cad4-5e21-4df9-81c5-d4d5b26d6688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S-w7hH2eioQO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}